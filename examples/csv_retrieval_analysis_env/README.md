# CSV Retrieval and Analysis Environment Example

This example demonstrates a complete workflow involving:
1.  Loading data from a CSV file.
2.  Storing the data in a ChromaDB vector store.
3.  Setting up a retrieval mechanism.
4.  Defining an analytical agent.
5.  Using an `Environment` to manage and execute the agent for analyzing retrieved data.

## Directory Structure

```
csv_retrieval_analysis_env/
├── sample_data.csv         # Sample CSV data for ingestion
├── config_env.py           # Configuration for this example (paths, model names)
├── data_loader_env.py      # Script to load CSV data into ChromaDB
├── analyzer_agent_def.py   # Definition of the ResultAnalyzerAgentEnv
└── main_env.py             # Main script to orchestrate the example
```

## Prerequisites

Before running this example, ensure you have the following:

1.  **Python Environment**: A working Python environment (e.g., Python 3.9+).
2.  **Project Dependencies**: All dependencies for the main `agentic-orchestrator` project installed. This typically includes:
    *   `langchain`
    *   `langchain-openai` (or other LLM provider libraries)
    *   `chromadb`
    *   `pandas` (often used by CSV loaders)
    *   `tiktoken`
    *   Other libraries specified in your project's `requirements.txt`.
3.  **OpenAI API Key**: If you are using OpenAI models (as configured by default in `config_env.py`), you must have your `OPENAI_API_KEY` environment variable set.
    ```bash
    export OPENAI_API_KEY="your_openai_api_key_here"
    ```

## Files Overview

### `sample_data.csv`
A simple CSV file containing data to be ingested. It should have an `id` column and a `text` column that will be used for embeddings, along with any other metadata columns (e.g., `category`).

**Example Content:**
```csv
id,text,category
1,"The sky is blue and vast.","nature"
2,"Apples are a healthy fruit, often red or green.","food"
3,"Software development requires careful planning and execution.","tech"
```

### `config_env.py`
This file contains configuration variables for the example, such as file paths for the CSV and ChromaDB, and names of the embedding and chat models to be used.

### `data_loader_env.py`
This script is responsible for:
*   Reading data from `sample_data.csv`.
*   Initializing an embedding model (e.g., from OpenAI via `EmbeddingClient`).
*   Using `DataLoaderFactory` to load and process the CSV data into LangChain `Document` objects.
*   Storing these documents in a persistent `ChromaStore` using the `DataWriter`.
It can be run independently to populate the vector store:
```bash
python -m examples.csv_retrieval_analysis_env.data_loader_env
```

### `analyzer_agent_def.py`
Defines the `ResultAnalyzerAgentEnv` class, which inherits from `OpenAIToolAgent`.
*   It is initialized with a specific system prompt (`ANALYZER_SYSTEM_PROMPT_ENV`) that instructs the LLM on how to analyze the applicability of a sentence to a fetched text result.
*   The agent's core logic for analysis is driven by its system prompt and the input it receives.

### `main_env.py`
This is the main script that orchestrates the entire example:
1.  **Initialization**: Sets up LLM and embedding clients.
2.  **Data Loading**: Calls `load_csv_to_chroma_env()` to ensure data is in the vector store.
3.  **Environment Setup**: Creates an `Environment` instance named "CSVDataAnalysisEnvironment".
4.  **Agent Addition**: Instantiates `ResultAnalyzerAgentEnv` and adds it to the environment.
5.  **Retriever Setup**:
    *   Initializes `ChromaStore` pointing to the persisted database.
    *   Creates a basic retriever using `RetrieverFactory`.
6.  **Execution**:
    *   Performs a document retrieval based on a sample query.
    *   Formats an input query for the `ResultAnalyzerAgentEnv`, including the sentence to check and the fetched document content.
    *   Uses `environment.execute_task()` to run the analysis task with the designated agent.
    *   Prints the analysis report generated by the agent.

## How to Run

1.  **Navigate to Project Root**: Open your terminal and go to the root directory of your `simple_chains` (or `agentic-orchestrator`) project.
2.  **Set API Key**: Ensure your `OPENAI_API_KEY` is set if using OpenAI models.
3.  **Run the Main Script**:
    ```bash
    python -m examples.csv_retrieval_analysis_env.main_env
    ```

## Expected Output

The script will output:
*   Logs indicating data loading progress.
*   Information about the agent being added to the environment.
*   The query used for retrieval and the content of the fetched document.
*   A detailed analysis report from the `ResultAnalyzerAgentEnv`, stating whether the sentence is applicable, the reasoning, and if not applicable, what's missing and suggestions for a match.

This example showcases how to integrate data ingestion, storage, retrieval, and agent-based processing within a managed `Environment`, leveraging the various components of the `agentic-orchestrator` framework.
```